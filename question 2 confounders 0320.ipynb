{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question2 With confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from linearmodels import IV2SLS\n",
    "from tqdm import tqdm\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz as gr\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG without confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"134pt\" height=\"116pt\"\r\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- Y -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>Y</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\r\n",
       "</g>\r\n",
       "<!-- T&#45;&gt;Y -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>T&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.3496,-72.7646C39.7115,-64.2831 45.1469,-53.7144 50.0413,-44.1974\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.2346,-45.6409 54.6957,-35.1473 47.0096,-42.4395 53.2346,-45.6409\"/>\r\n",
       "</g>\r\n",
       "<!-- X -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>X</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\r\n",
       "</g>\r\n",
       "<!-- X&#45;&gt;Y -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>X&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.6504,-72.7646C86.2885,-64.2831 80.8531,-53.7144 75.9587,-44.1974\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.9904,-42.4395 71.3043,-35.1473 72.7654,-45.6409 78.9904,-42.4395\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x25d999ba4c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG with confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: %3 Pages: 1 -->\r\n",
       "<svg width=\"134pt\" height=\"188pt\"\r\n",
       " viewBox=\"0.00 0.00 134.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\r\n",
       "<title>%3</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 130,-184 130,4 -4,4\"/>\r\n",
       "<!-- T -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>T</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\r\n",
       "</g>\r\n",
       "<!-- Y -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>Y</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\r\n",
       "</g>\r\n",
       "<!-- T&#45;&gt;Y -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>T&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.6504,-72.7646C86.2885,-64.2831 80.8531,-53.7144 75.9587,-44.1974\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.9904,-42.4395 71.3043,-35.1473 72.7654,-45.6409 78.9904,-42.4395\"/>\r\n",
       "</g>\r\n",
       "<!-- W -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>W</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">W</text>\r\n",
       "</g>\r\n",
       "<!-- W&#45;&gt;T -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>W&#45;&gt;T</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99,-143.697C99,-135.983 99,-126.712 99,-118.112\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.5,-118.104 99,-108.104 95.5001,-118.104 102.5,-118.104\"/>\r\n",
       "</g>\r\n",
       "<!-- X -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>X</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\r\n",
       "</g>\r\n",
       "<!-- X&#45;&gt;Y -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>X&#45;&gt;Y</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.3496,-72.7646C39.7115,-64.2831 45.1469,-53.7144 50.0413,-44.1974\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.2346,-45.6409 54.6957,-35.1473 47.0096,-42.4395 53.2346,-45.6409\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x25d99bbeb20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"Y\")\n",
    "\n",
    "g.edge(\"W\", \"T\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cov(dim, corr):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc, axis=0)\n",
    "\n",
    "\n",
    "def generate_multnorm(nobs, corr, nvar):\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc=1, scale=.5, size=(nvar, 1)))) ** (1 / 2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i], std[i], nobs), (nobs, -1)))\n",
    "\n",
    "    normvars = np.concatenate(acc, axis=1)\n",
    "\n",
    "    cov = generate_cov(nvar, corr)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    X = np.transpose(np.dot(C, np.transpose(normvars)))\n",
    "    return X\n",
    "\n",
    "\n",
    "def randomize_treatment(N, prob=0.5):\n",
    "    return np.random.binomial(1, prob, N).reshape([N, 1])\n",
    "\n",
    "\n",
    "def generate_data(tau, N, p, corr=0.5):\n",
    "    \"\"\"p is the number of covariates\"\"\"\n",
    "    X = generate_multnorm(N, corr, p)\n",
    "    W= X+generate_multnorm(N, corr, p)\n",
    "    T = randomize_treatment(N) \n",
    "    global beta\n",
    "    global err\n",
    "    global gamma\n",
    "    gamma=np.random.normal(5, 5, [p, 1])\n",
    "    err = np.random.normal(0, 1, [N, 1])\n",
    "    beta = np.random.normal(5, 5, [p, 1])\n",
    "\n",
    "    Y=tau * T + X @ beta +W @gamma+  err\n",
    "    return W,Y, T, X\n",
    "\n",
    "\n",
    "def randomized_experiment(tau, N, p, violate=False):\n",
    "  \n",
    "    W,Y, T, X = generate_data(tau, N, p)  \n",
    "    covars = np.concatenate([T, X,W], axis=1)\n",
    "    if violate==True:\n",
    "        covars = np.concatenate([T,X], axis=1)\n",
    "        \n",
    "    mod = sm.OLS(Y, covars)\n",
    "    res = mod.fit()\n",
    "    tauhat = res.params[0]\n",
    "    se_tauhat = res.HC1_se[0]\n",
    "    return tauhat, se_tauhat\n",
    "\n",
    "\n",
    "def get_bias_rmse_size(true_value, estimate: list, standard_error: list, cval = 1.96):\n",
    "    R = len(estimate)\n",
    "#     estimate = np.array(estimate).reshape([R, 1])\n",
    "#     standard_error = np.array(standard_error).reshape([R, 1])\n",
    "    b = estimate - np.ones([R, 1]) * true_value\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b ** 2))\n",
    "    tval = b / standard_error\n",
    "    size = np.mean(1 * (np.abs(tval) > cval))\n",
    "    return bias, rmse, size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without controlling confounders\n",
    "violate==True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1110.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average estimate value and standard error are: 5.016886630325147 5.790207661827128\n",
      "bias, rmse, size are: 0.01688663 6.19904019 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the case when the assumption holds\n",
    "tauhats = []\n",
    "se_tauhats = []\n",
    "for _ in tqdm(range(R)):\n",
    "    tauhat, se_tauhat = randomized_experiment(tau, N, p, violate=True)\n",
    "    tauhats.append(tauhat)\n",
    "    se_tauhats.append(se_tauhat)\n",
    "    \n",
    "tauhats = np.array(tauhats).reshape([R, 1])\n",
    "se_tauhats = np.array(se_tauhats).reshape([R, 1])\n",
    "print(\"Average estimate value and standard error are:\", tauhats.mean(), se_tauhats.mean())\n",
    "\n",
    "bias, rmse, size = get_bias_rmse_size(tau, tauhats, se_tauhats)\n",
    "print(\"bias, rmse, size are:\", round(bias, 8), round(rmse, 8), round(size, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1109.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average estimate value and standard error are: 5.187498981887106 5.641856949355985\n",
      "bias, rmse, size are: 0.18749898 5.81458593 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 100  # number of observations\n",
    "tau = 5  # treatment effect\n",
    "p = 10  # number of covariates\n",
    "R = 500  # number of experiments\n",
    "# This is the case when the assumption holds\n",
    "tauhats = []\n",
    "se_tauhats = []\n",
    "for _ in tqdm(range(R)):\n",
    "    tauhat, se_tauhat = randomized_experiment(tau, N, p, violate=True)\n",
    "    tauhats.append(tauhat)\n",
    "    se_tauhats.append(se_tauhat)\n",
    "    \n",
    "tauhats = np.array(tauhats).reshape([R, 1])\n",
    "se_tauhats = np.array(se_tauhats).reshape([R, 1])\n",
    "print(\"Average estimate value and standard error are:\", tauhats.mean(), se_tauhats.mean())\n",
    "\n",
    "bias, rmse, size = get_bias_rmse_size(tau, tauhats, se_tauhats)\n",
    "print(\"bias, rmse, size are:\", round(bias, 8), round(rmse, 8), round(size, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real World example\n",
    " The real life example would be say, run an experiment where you seperate some students into two groups and give them a particular task, one of the groups with motivation like lipstics and the other without it. And the goal is to see how the motivation improves their task performance. \n",
    " There is no control for confounders here. Which means "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling confounders\n",
    "\n",
    "violate==False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 465.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average estimate value and standard error are: 4.996652128035831 0.04522657390680687\n",
      "bias, rmse, size are: -0.00334787 0.04345946 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N = 1000  # number of observations\n",
    "tau = 5  # treatment effect\n",
    "p = 10  # number of covariates\n",
    "R = 500  # number of experiments\n",
    "# This is the case when the assumption is violated\n",
    "tauhats = []\n",
    "se_tauhats = []\n",
    "for _ in tqdm(range(R)):\n",
    "    tauhat, se_tauhat = randomized_experiment(tau, N, p, violate=False)\n",
    "    tauhats.append(tauhat)\n",
    "    se_tauhats.append(se_tauhat)\n",
    "    \n",
    "tauhats = np.array(tauhats).reshape([R, 1])\n",
    "se_tauhats = np.array(se_tauhats).reshape([R, 1])\n",
    "print(\"Average estimate value and standard error are:\", tauhats.mean(),se_tauhats.mean())\n",
    "\n",
    "bias, rmse, size = get_bias_rmse_size(tau, tauhats, se_tauhats)\n",
    "print(\"bias, rmse, size are:\", round(bias, 8), round(rmse, 8), round(size, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100  # number of observations\n",
    "tau = 5  # treatment effect\n",
    "p = 10  # number of covariates\n",
    "R = 500  # number of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 970.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average estimate value and standard error are: 5.006387741629792 0.1558486490281588\n",
      "bias, rmse, size are: 0.00638774 0.15363804 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is the case when the assumption is violated\n",
    "tauhats = []\n",
    "se_tauhats = []\n",
    "for _ in tqdm(range(R)):\n",
    "    tauhat, se_tauhat = randomized_experiment(tau, N, p, violate=False)\n",
    "    tauhats.append(tauhat)\n",
    "    se_tauhats.append(se_tauhat)\n",
    "    \n",
    "tauhats = np.array(tauhats).reshape([R, 1])\n",
    "se_tauhats = np.array(se_tauhats).reshape([R, 1])\n",
    "print(\"Average estimate value and standard error are:\", tauhats.mean(),se_tauhats.mean())\n",
    "\n",
    "bias, rmse, size = get_bias_rmse_size(tau, tauhats, se_tauhats)\n",
    "print(\"bias, rmse, size are:\", round(bias, 8), round(rmse, 8), round(size, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Life Example\n",
    "The real life example would be say, run an experiment where you seperate some students into two groups and give them a particular task, one of the groups with motivation like lipstics and the other without it. And the goal is to see how the motivation improves their task performance. \n",
    " We still include covariates including age, family background(Single parent or not), parents' education level, ethnic, gender,height, birth period,family income, family location, household income.\n",
    " However, there will be a confounder, which is the perference for lipstics. The prefernce for lipstics clearly correlated with the treatment.\n",
    " With this confounder, we continue study how the motivation improves theier task performance."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
